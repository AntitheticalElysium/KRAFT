{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prep-md-intro",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "**Goal:** Load raw data from the KuaiRec dataset (`small_matrix.csv`, `item_categories.csv`), process it, perform a time-based split, and save the results into the required format:\n",
    "*   `../data/interactions_train.csv`\n",
    "*   `../data/interactions_test.csv`\n",
    "*   `../data/video_metadata.csv`\n",
    "*   `../data/sample_submission.csv`\n",
    "*   `../data/test_user_item_map.pkl` (Ground truth for evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-setup",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import libraries and define file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prep-code-imports-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_DATA_DIR = \"../raw_data/KuaiRec/data/\"\n",
    "PROCESSED_DATA_DIR = \"../data/\"\n",
    "POSITIVE_INTERACTION_THRESHOLD = 1.0 # Define positive interaction (watch_ratio >= 1.0)\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "# Input file paths\n",
    "raw_interactions_path = os.path.join(RAW_DATA_DIR, \"small_matrix.csv\")\n",
    "raw_item_categories_path = os.path.join(RAW_DATA_DIR, \"item_categories.csv\")\n",
    "\n",
    "# Output file paths\n",
    "output_video_metadata_path = os.path.join(PROCESSED_DATA_DIR, \"video_metadata.csv\")\n",
    "output_train_path = os.path.join(PROCESSED_DATA_DIR, \"interactions_train.csv\")\n",
    "output_test_path = os.path.join(PROCESSED_DATA_DIR, \"interactions_test.csv\")\n",
    "output_sample_submission_path = os.path.join(PROCESSED_DATA_DIR, \"sample_submission.csv\")\n",
    "output_ground_truth_path = os.path.join(PROCESSED_DATA_DIR, \"test_user_item_map.pkl\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-load-raw",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prep-code-load-raw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw interactions from: ../raw_data/KuaiRec/data/small_matrix.csv\n",
      "Loading raw item categories from: ../raw_data/KuaiRec/data/item_categories.csv\n",
      "Loaded 4676570 interactions and metadata for 10728 items.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading raw interactions from: {raw_interactions_path}\")\n",
    "try:\n",
    "    interactions_df = pd.read_csv(raw_interactions_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Interaction file not found at {raw_interactions_path}. Ensure data is downloaded.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loading raw item categories from: {raw_item_categories_path}\")\n",
    "try:\n",
    "    item_categories_df = pd.read_csv(raw_item_categories_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Item categories file not found at {raw_item_categories_path}. Ensure data is downloaded.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {len(interactions_df)} interactions and metadata for {len(item_categories_df)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-create-metadata",
   "metadata": {},
   "source": [
    "## Create `video_metadata.csv`\n",
    "Select relevant columns from item categories and rename `video_id` to `item_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prep-code-create-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing item metadata...\n",
      "Saved processed video metadata to: ../data/video_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing item metadata...\")\n",
    "video_metadata_df = item_categories_df.rename(columns={'video_id': 'item_id'})\n",
    "video_metadata_df = video_metadata_df[['item_id', 'feat']]\n",
    "\n",
    "video_metadata_df.to_csv(output_video_metadata_path, index=False)\n",
    "print(f\"Saved processed video metadata to: {output_video_metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-process-interactions",
   "metadata": {},
   "source": [
    "## Process Interactions\n",
    "1. Rename `video_id` to `item_id`.\n",
    "2. Define `positive_interaction` based on `watch_ratio`.\n",
    "3. Sort interactions by `timestamp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prep-code-process-interactions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing interactions data...\n",
      "Defined 'positive_interaction' using threshold: 1.0\n",
      "positive_interaction\n",
      "0    0.676034\n",
      "1    0.323966\n",
      "Name: proportion, dtype: float64\n",
      "Interactions sorted by timestamp.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing interactions data...\")\n",
    "# Rename column\n",
    "interactions_df = interactions_df.rename(columns={'video_id': 'item_id'})\n",
    "\n",
    "# Define positive interaction \n",
    "# Justification: Choosing watch_ratio >= 1.0 implies the user watched at least the full video duration.\n",
    "# This is a reasonable heuristic for positive engagement, though other thresholds could be explored.\n",
    "interactions_df['positive_interaction'] = (interactions_df['watch_ratio'] >= POSITIVE_INTERACTION_THRESHOLD).astype(int)\n",
    "print(f\"Defined 'positive_interaction' using threshold: {POSITIVE_INTERACTION_THRESHOLD}\")\n",
    "print(interactions_df['positive_interaction'].value_counts(normalize=True))\n",
    "\n",
    "# Sort by timestamp for chronological split\n",
    "interactions_df = interactions_df.sort_values('timestamp').reset_index(drop=True)\n",
    "print(\"Interactions sorted by timestamp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-split",
   "metadata": {},
   "source": [
    "## Time-Based Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prep-code-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data: 3741256 train interactions, 935314 test interactions.\n"
     ]
    }
   ],
   "source": [
    "split_index = int(len(interactions_df) * TRAIN_RATIO)\n",
    "\n",
    "train_df = interactions_df.iloc[:split_index].copy()\n",
    "test_df = interactions_df.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"Split data: {len(train_df)} train interactions, {len(test_df)} test interactions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-save-train",
   "metadata": {},
   "source": [
    "## Create and Save `interactions_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prep-code-save-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training interactions to: ../data/interactions_train.csv\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep_train = ['user_id', 'item_id', 'watch_ratio', 'timestamp', 'positive_interaction']\n",
    "interactions_train_df = train_df[cols_to_keep_train]\n",
    "\n",
    "interactions_train_df.to_csv(output_train_path, index=False)\n",
    "print(f\"Saved training interactions to: {output_train_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-save-test",
   "metadata": {},
   "source": [
    "## Create and Save `interactions_test.csv`\n",
    "Contains only `user_id`, `item_id` pairs for prediction. Users not seen in training are filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prep-code-save-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test set to 935314 interactions from users seen in training.\n",
      "Saved 935314 unique test user-item pairs to: ../data/interactions_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter test set for users present in the training set (common practice)\n",
    "train_users = train_df['user_id'].unique()\n",
    "test_df_filtered = test_df[test_df['user_id'].isin(train_users)].copy()\n",
    "print(f\"Filtered test set to {len(test_df_filtered)} interactions from users seen in training.\")\n",
    "\n",
    "# Select only user_id and item_id, remove duplicates\n",
    "interactions_test_df = test_df_filtered[['user_id', 'item_id']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "interactions_test_df.to_csv(output_test_path, index=False)\n",
    "print(f\"Saved {len(interactions_test_df)} unique test user-item pairs to: {output_test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-save-groundtruth",
   "metadata": {},
   "source": [
    "## Store Test Ground Truth (`test_user_item_map.pkl`)\n",
    "Create a map of user -> set of positive items from the test period for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prep-code-save-groundtruth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test ground truth map for 1411 users to: ../data/test_user_item_map.pkl\n"
     ]
    }
   ],
   "source": [
    "test_ground_truth_df = test_df_filtered[test_df_filtered['positive_interaction'] == 1]\n",
    "test_user_item_map = test_ground_truth_df.groupby('user_id')['item_id'].agg(set).to_dict()\n",
    "\n",
    "with open(output_ground_truth_path, 'wb') as f:\n",
    "    pickle.dump(test_user_item_map, f)\n",
    "print(f\"Saved test ground truth map for {len(test_user_item_map)} users to: {output_ground_truth_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-save-sample",
   "metadata": {},
   "source": [
    "## Create and Save `sample_submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prep-code-save-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample submission file to: ../data/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "sample_submission_df = interactions_test_df.copy()\n",
    "sample_submission_df['score'] = 0.5 # Placeholder score\n",
    "\n",
    "sample_submission_df.to_csv(output_sample_submission_path, index=False)\n",
    "print(f\"Saved sample submission file to: {output_sample_submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prep-md-summary",
   "metadata": {},
   "source": [
    "## Completion Summary\n",
    "Data preparation complete. The required files have been generated in the `../data/` directory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
